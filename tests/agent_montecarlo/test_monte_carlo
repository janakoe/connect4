import numpy as np

from agents.common import NO_PLAYER, PLAYER1, \
    PLAYER2, initialize_game_state, PlayerAction, \
    PLAYER2_PRINT, PLAYER1_PRINT


def test_generate_move():
    from agents.agent_montecarlo import generate_move
    assert NotImplementedError



def test_select():
    from agents.agent_montecarlo.monte_carlo import MonteCarlo
    # select maximal child
    board = initialize_game_state()
    player = np.random.choice([PLAYER1, PLAYER2])
    mcst = MonteCarlo(board, player, explore_param=np.sqrt(2))
    node = mcst.select(mcst.root)

    assert True
    if not all(node.children.values()):
        print('not all(node.children.values()) == True ')
    #MonteCarlo.select()



    # phase 2 - Expansion: Expand a random unexpanded child node
#def test_expansion():
#    from agents.agent_montecarlo import MonteCarlo
#    raise NotImplementedError

# phase 3 - Simulation: Play game to terminal state, return winner
#def test_simulation():
#    from agents.agent_montecarlo import MonteCarlo
#    raise NotImplementedError

# phase 4 - Backpropagation: Update ancestor statistics
#def test_backprop(node, winner):
#    from agents.agent_montecarlo import MonteCarlo

#    raise NotImplementedError
